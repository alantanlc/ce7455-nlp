{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "nlp-from-scratch-translation-with-a-sequence-to-sequence-network-and-attention.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alanwuha/ce7455-nlp/blob/master/assignment-3/nlp-from-scratch-translation-with-a-sequence-to-sequence-network-and-attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kf6lYotpAas",
        "colab_type": "text"
      },
      "source": [
        "# NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0ohF3QFc-Sb",
        "colab_type": "text"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyVY5MIopAav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQHFVnKP_DFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c742b0a8-f1ba-45df-8843-c6c7173decad"
      },
      "source": [
        "!pip install torchtext==0.2.3"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.2.3 in /usr/local/lib/python3.6/dist-packages (0.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (2019.11.28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0iUnH9VpAa1",
        "colab_type": "text"
      },
      "source": [
        "### Load and Prepare Data\n",
        "\n",
        "The data for this project is a set of many thousands of English to French translation pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmdQD0tQpAa2",
        "colab_type": "code",
        "outputId": "42fe6e86-dcdc-4f93-ee22-439fde49bc97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-02 05:53:25--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.224.253.59, 13.224.253.92, 13.224.253.46, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.224.253.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-04-02 05:53:25 (27.7 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVYaTPe4pAa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = { 0: 'SOS', 1: 'EOS' }\n",
        "        self.n_words = 2 # Count SOS and EOS\n",
        "        \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "            \n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7QYWG2opAbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aa6f8564-6ff4-4ee8-a330-a3f15c41af47",
        "id": "vr8PjTrnh1A1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(unicodeToAscii(\"À l'aide !\"))\n",
        "print(normalizeString(\"À l'aide !\"))\n",
        "\n",
        "print(normalizeString(\"Go.\"))\n",
        "print(normalizeString(\"Va !\"))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A l'aide !\n",
            "a l aide !\n",
            "go .\n",
            "va !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q965XNzpAbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p): # e.g. p = ['go.', 'va !']\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omy7HbdcpxPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wordIndexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = wordIndexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQiqvKdSpAbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False): # e.g. lang1 = eng, lang2 = fra\n",
        "    print(\"Reading lines...\")\n",
        "    \n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "    \n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    \n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "        input_char = Char(lang2)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "        input_char = Char(lang1)\n",
        "        \n",
        "    return input_lang, output_lang, input_char, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q5vqey1pAb0",
        "colab_type": "text"
      },
      "source": [
        "### The Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdbqxzumpAb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UEvTmt8pAb5",
        "colab_type": "text"
      },
      "source": [
        "### The Attention Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtPmQBvcpAb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "        \n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "        \n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "        \n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "        \n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        \n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        \n",
        "        return output, hidden, attn_weights\n",
        "    \n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuIByMVfpAca",
        "colab_type": "text"
      },
      "source": [
        "### Plotting results\n",
        "\n",
        "Plotting is done with matplotlib, using the array of loss values `plot_losses` saved while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuK6-GWApAca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "def showPlot(points):\n",
        "    print('showPlot')\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locater puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtm7keUhpAcQ",
        "colab_type": "text"
      },
      "source": [
        "This is a helper function to print time elapsed and estimated time remaining given the current time and progress %."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdnEx96qpAcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = s // 60\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    # return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "    return '%s' % (asMinutes(s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULnxkv_TkYmX",
        "colab_type": "text"
      },
      "source": [
        "## Here's What's Changed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PNMvZqupAbj",
        "colab_type": "text"
      },
      "source": [
        "### The CNN Model for Generating Character Embeddings\n",
        "\n",
        "Consider the word 'cat', we pad it on both ends to get our maximum word length (this is mainly an implementation quirk since we can't have variable length layers at run time, our algorithm will ignore the pads).\n",
        "\n",
        "We then apply a convolution layer on top that generates spatial coherence across characters, we use a maxpool to extract meaningful features out of our convolution layer. This now gives us a dense vector representation of each word.\n",
        "\n",
        "__This representation will then be concatenated with the word embedding to become the input of the GRU layer in EncoderRNN__.\n",
        "\n",
        "![cnn_model](https://raw.githubusercontent.com/TheAnig/NER-LSTM-CNN-Pytorch/master/images/cnn_model.png)\n",
        "\n",
        "This snippet shows us how the CNN is implemented in PyTorch.\n",
        "\n",
        "```\n",
        "self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=char_representation_dim, kernel_size=(3, char_embedding_dim), padding=(2, 0))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O27J5z9xh2ey",
        "colab_type": "text"
      },
      "source": [
        "We define a new `Char` class that stores the char2index, char2count, and index2char dictionaries for a given language to be used for character-level encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6qWLGLfpAbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EOS_char_token = 0\n",
        "\n",
        "class Char:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.char2index = {}\n",
        "        self.char2count = {}\n",
        "        self.index2char = {0: '*'}\n",
        "        self.n_chars = 1\n",
        "        \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "            \n",
        "    def addWord(self, word):\n",
        "        for char in word:\n",
        "            self.addChar(char)\n",
        "            \n",
        "    def addChar(self, char):\n",
        "        if char not in self.char2index:\n",
        "            self.char2index[char] = self.n_chars\n",
        "            self.char2count[char] = 1\n",
        "            self.index2char[self.n_chars] = char\n",
        "            self.n_chars += 1\n",
        "        else:\n",
        "            self.char2count[char] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFCjZYqtqL3l",
        "colab_type": "text"
      },
      "source": [
        "We add two new methods `charIndexesFromSentence` and `charIndexesFromWord` to retrieve character indexes for a given input sentence to be used for our character-level encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC6OW8jHqLLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def charIndexesFromSentence(char, sentence):\n",
        "    indexes = [charIndexesFromWord(char, word) for word in sentence.split(' ')]\n",
        "    indexes.append([EOS_char_token])\n",
        "    return indexes\n",
        "\n",
        "def charIndexesFromWord(char, word):\n",
        "    return [char.char2index[character] for character in word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipDhqcoxOeqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4ba11f7-71d3-48fc-802f-54534791b937"
      },
      "source": [
        "charIndexesFromSentence(input_char, 'je t amie .')"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 6], [16], [1, 15, 2, 6], [5], [0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GibMll--lA07",
        "colab_type": "text"
      },
      "source": [
        "### The Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmP2nw1geG-y",
        "colab_type": "text"
      },
      "source": [
        "We modify the original EncoderRNN to include a character-level encoder that generates character representation given an input word. This character representation will then be concatenated with the word embedding and passed as input into the GRU layer to generate the output and hidden vectors for each word in a sequence.\n",
        "\n",
        "![diagram](/content/encoder.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0rMmhzZpAbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, n_chars, n_words, hidden_size, char_embedding_dim=25, char_representation_dim=25):\n",
        "        \"\"\"\n",
        "        Input parameters:\n",
        "            n_chars = Number of unique characters in input language\n",
        "            n_words = Number of unique words in input language\n",
        "            hidden_size = Dimension of GRU input and output.\n",
        "            char_embedding_dim = Dimension of the character embeddings\n",
        "            char_representation_dim = Output dimension from the CNN encoder for character\n",
        "        \"\"\"\n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "        # Parameters\n",
        "        self.n_chars = n_chars\n",
        "        self.char_embedding_dim = char_embedding_dim\n",
        "        self.char_representation_dim = char_representation_dim\n",
        "        self.n_words = n_words\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Character-level encoder\n",
        "        self.char_embedding_layer = nn.Embedding(n_chars, char_embedding_dim)\n",
        "        self.char_cnn3_layer = nn.Conv2d(in_channels=1, out_channels=char_representation_dim, kernel_size=(3, char_embedding_dim), padding=(2, 0))\n",
        "        \n",
        "        # Word embedding layer (Dimension of the word embeddings is automatically derived as hidden_size - char_representation_dim)\n",
        "        self.word_embedding_layer = nn.Embedding(n_words, hidden_size - char_representation_dim)\n",
        "        \n",
        "        # GRU layer\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "        # Weights\n",
        "        self.initEmbedding(self.char_embedding_layer.weight)\n",
        "        \n",
        "    def forward(self, char_indexes, word_index, hidden):\n",
        "        # Get char representation\n",
        "        char_embedding = self.char_embedding_layer(char_indexes).unsqueeze(1)\n",
        "        char_cnn3 = self.char_cnn3_layer(char_embedding).squeeze(-1).unsqueeze(1)\n",
        "        char_representation = F.max_pool2d(char_cnn3, kernel_size=(1, char_cnn3.size(-1))).squeeze(-1)\n",
        "\n",
        "        # Get word embedding\n",
        "        word_embedding = self.word_embedding_layer(word_index).view(1, 1, -1)\n",
        "\n",
        "        # Concatenate char representation with word embedding\n",
        "        combined = torch.cat((char_representation, word_embedding), dim=2)\n",
        "\n",
        "        # Feed combined and hidden to GRU\n",
        "        output, hidden = self.gru(combined, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "    \n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "    def initEmbedding(self, input_embedding):\n",
        "      \"\"\"\n",
        "      Initialize embedding\n",
        "      \"\"\"\n",
        "      bias = np.sqrt(3.0 / input_embedding.size(1))\n",
        "      nn.init.uniform_(input_embedding, -bias, bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pONQk1yseUbp",
        "colab_type": "text"
      },
      "source": [
        "### Decoder Beam Search\n",
        "\n",
        "We implement a new class `BeamSearchNode` and new method `BeamDecode` to perform beam search decoding in our decoder model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFxffk4seX35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BeamSearchNode(object):\n",
        "  def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
        "    self.h = hiddenstate\n",
        "    self.prevNode = previousNode\n",
        "    self.wordid = wordId\n",
        "    self.logp = logProb\n",
        "    self.leng = length\n",
        "\n",
        "  def eval(self, alpha=1.0):\n",
        "    reward = 0\n",
        "    # Add here a function for shaping a reward\n",
        "\n",
        "    return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiJ-qnIfgoMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator\n",
        "from queue import PriorityQueue\n",
        "\n",
        "def beamDecode(decoder_hiddens, decoder, encoder_outputs=None):\n",
        "  \"\"\"\n",
        "  :param decoder_hidden: input tensor of shape [1, B, H] for start of the decoding\n",
        "  :param encoder_outputs: if you are using attention mechanism you can pass encoder outputs, [T, B, H] where T is the maximum length of input sentence\n",
        "  :return: decoded_batch\n",
        "  \"\"\"\n",
        "\n",
        "  beam_width = 5\n",
        "  topk = 1 # how many sentences do you want to generate\n",
        "  decoded_batch = []\n",
        "\n",
        "  # print(target_tensor.shape)\n",
        "  # print(decoder_hiddens.shape)\n",
        "  # print(encoder_outputs.shape)\n",
        "\n",
        "  # decoding goes sentence by sentence\n",
        "  for idx in range(decoder_hiddens.size(1)):\n",
        "    decoder_hidden = decoder_hiddens[:, idx, :]\n",
        "    encoder_output = encoder_outputs[:, idx, :]\n",
        "\n",
        "    # Start with the start of the sentence token\n",
        "    decoder_input = torch.LongTensor([[SOS_token]]).to(device)\n",
        "    \n",
        "    # Number of sentence to generate\n",
        "    endnodes = []\n",
        "    number_required = min((topk + 1), topk - len(endnodes))\n",
        "\n",
        "    # Starting node - hidden vector, previous node, word id, logp, length\n",
        "    node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
        "    nodes = PriorityQueue()\n",
        "\n",
        "    # Start the queue\n",
        "    nodes.put((-node.eval(), node))\n",
        "    qsize = 1\n",
        "\n",
        "    # Start beam search\n",
        "    while True:\n",
        "\n",
        "      # Give up when decoding takes too long\n",
        "      if qsize > 2000:\n",
        "        break\n",
        "\n",
        "      # Fetch the best node\n",
        "      score, n = nodes.get()\n",
        "      decoder_input = n.wordid\n",
        "      decoder_hidden = n.h\n",
        "\n",
        "      if n.wordid.item() == EOS_token and n.prevNode != None:\n",
        "        endnodes.append((score, n))\n",
        "        # If we reached maximum # of sentences required\n",
        "        if len(endnodes) >= number_required:\n",
        "          break\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "      # Decode for one step using decoder\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "\n",
        "      # PUT HERE REAL BEAM SEARCH OF TOP\n",
        "      log_prob, indexes = torch.topk(decoder_output, beam_width)\n",
        "      # print(indexes)\n",
        "      nextnodes = []\n",
        "\n",
        "      for new_k in range(beam_width):\n",
        "        decoded_t = indexes[0][new_k].view(1, -1)\n",
        "        log_p = log_prob[0][new_k].item()\n",
        "\n",
        "        node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
        "        score = -node.eval()\n",
        "        nextnodes.append((score, node))\n",
        "\n",
        "      # Put them into queue\n",
        "      for i in range(len(nextnodes)):\n",
        "        score, nn = nextnodes[i]\n",
        "        nodes.put((score, nn))\n",
        "        # increase qsize\n",
        "      qsize += len(nextnodes) - 1\n",
        "\n",
        "    # Choose nbest paths, back trace them\n",
        "    if len(endnodes) == 0:\n",
        "      endnodes = [nodes.get() for _ in range(topk)]\n",
        "\n",
        "    utterances = []\n",
        "    for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
        "      utterance = []\n",
        "      utterance.append(n.wordid)\n",
        "      # back trace\n",
        "      while n.prevNode != None:\n",
        "        n = n.prevNode\n",
        "        utterance.append(n.wordid)\n",
        "\n",
        "      utterance = utterance[::-1]\n",
        "      utterances.append(utterance)\n",
        "    \n",
        "    decoded_batch.append(utterances)\n",
        "\n",
        "  return decoded_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhLEvBd-pAbP",
        "colab_type": "text"
      },
      "source": [
        "### Preparing the train and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRcfjbwtpAbZ",
        "colab_type": "text"
      },
      "source": [
        "We modify `prepareData` to:\n",
        "1. Generate `input_char`\n",
        "1. Shuffle `pairs`\n",
        "1. Split `pairs` into `train_pairs` (80% of total pairs) and `test_pairs` (20% of total pairs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YdVVufWmpAba",
        "colab_type": "code",
        "outputId": "a94a11b5-ba7c-4d34-cfad-b6b922bc310e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, input_char, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words and chars...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "        input_char.addSentence(pair[0])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    print(\"Counted chars:\")\n",
        "    print(input_char.name, input_char.n_chars)\n",
        "    print('%d total pairs' % (len(pairs),))\n",
        "\n",
        "    # Shuffle pairs and split into train_pairs and test_pairs\n",
        "    random.shuffle(pairs)\n",
        "    train_length = (len(pairs) // 10) * 8\n",
        "    train_pairs = pairs[:train_length]\n",
        "    test_pairs = pairs[train_length:]\n",
        "    \n",
        "    return input_lang, output_lang, input_char, train_pairs, test_pairs\n",
        "\n",
        "input_lang, output_lang, input_char, train_pairs, test_pairs = prepareData('eng', 'fra', True)\n",
        "\n",
        "print('\\nCounting total pairs, train pairs, and test pairs...')\n",
        "print('%d train pairs' % (len(train_pairs),))\n",
        "print('%d test pairs' % (len(test_pairs),))\n",
        "print('Example of a training pair: %s' % (train_pairs[0]))\n",
        "\n",
        "print('\\nTesting charIndexesFromSentence...')\n",
        "sentence = 'je t aime'\n",
        "print('Sentence: %s' % (sentence))\n",
        "print('Char Indexes: %s' % (charIndexesFromSentence(input_char, sentence)))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words and chars...\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "Counted chars:\n",
            "fra 30\n",
            "10599 total pairs\n",
            "\n",
            "Counting total pairs, train pairs, and test pairs...\n",
            "8472 train pairs\n",
            "2127 test pairs\n",
            "Example of a training pair: ['je me fais du souci a leur sujet .', 'i m worried about them .']\n",
            "\n",
            "Testing charIndexesFromSentence...\n",
            "Sentence: je t aime\n",
            "Char Indexes: [[1, 7], [17], [2, 3, 16, 7], [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEGVlMuW27R4",
        "colab_type": "text"
      },
      "source": [
        "There are a total of `29` unique characters (excluding the EOS_char_token '*' that we added)  in the `French` dataset as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MwV4fb0pAbe",
        "colab_type": "code",
        "outputId": "65fc7bed-cc1f-4c4f-9f4b-ec9a73ea1271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "print(input_char.char2index)\n",
        "print(input_char.char2count)\n",
        "print(input_char.index2char)\n",
        "print(len(input_char.char2index))"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'j': 1, 'a': 2, 'i': 3, 'n': 4, 's': 5, '.': 6, 'e': 7, 'v': 8, 'b': 9, 'c': 10, 'u': 11, 'g': 12, 'r': 13, 'o': 14, 'f': 15, 'm': 16, 't': 17, 'h': 18, '!': 19, 'l': 20, 'd': 21, 'p': 22, 'z': 23, 'x': 24, 'y': 25, 'q': 26, 'k': 27, '?': 28, 'w': 29}\n",
            "{'j': 4774, 'a': 13819, 'i': 15983, 'n': 15628, 's': 27771, '.': 10262, 'e': 40222, 'v': 4630, 'b': 1642, 'c': 5537, 'u': 16566, 'g': 1742, 'r': 12076, 'o': 13499, 'f': 2316, 'm': 6719, 't': 15608, 'h': 1468, '!': 197, 'l': 9856, 'd': 5313, 'p': 6098, 'z': 407, 'x': 747, 'y': 415, 'q': 1192, 'k': 37, '?': 145, 'w': 13}\n",
            "{0: '*', 1: 'j', 2: 'a', 3: 'i', 4: 'n', 5: 's', 6: '.', 7: 'e', 8: 'v', 9: 'b', 10: 'c', 11: 'u', 12: 'g', 13: 'r', 14: 'o', 15: 'f', 16: 'm', 17: 't', 18: 'h', 19: '!', 20: 'l', 21: 'd', 22: 'p', 23: 'z', 24: 'x', 25: 'y', 26: 'q', 27: 'k', 28: '?', 29: 'w'}\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx0-LqqZpAcJ",
        "colab_type": "text"
      },
      "source": [
        "In the `train` method, we modify the encoder's forward pass method (line 24) to take in character indexes for each input word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJhU76afpAcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, input_char_indexes, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        # Modify encoder forward pass method to take in character indexes of the input word\n",
        "        encoder_output, encoder_hidden = encoder(torch.LongTensor([input_char_indexes[ei]]).to(device), input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "        \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            # Train using DecoderRNN\n",
        "            # decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "\n",
        "            # Train using AttnDecoderRNN\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            # Train using DecoderRNN\n",
        "            # decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "\n",
        "            # Train using AttnDecoderRNN\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            \n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHutNXXIC6j5",
        "colab_type": "text"
      },
      "source": [
        "We define a new method `trainEpochs` to train on `train_pairs` (80% of the data) and evaluate on `test_pairs` (20% of the data) for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NorkrizapAcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainEpochs(encoder, decoder, n_epochs=20, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    # Train over n_epochs\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # Print start of epoch\n",
        "        print('Epoch %d' % (epoch))\n",
        "\n",
        "        # Shuffle train_pairs\n",
        "        random.shuffle(train_pairs)\n",
        "\n",
        "        # Get tensors from pair\n",
        "        training_pairs = [tensorsFromPair(pair) for pair in train_pairs]\n",
        "        \n",
        "        # Get character indexes\n",
        "        training_char_indexes = [charIndexesFromSentence(input_char, pair[0]) for pair in train_pairs]\n",
        "\n",
        "        # Train all train_pairs\n",
        "        for i in range(1, len(train_pairs) + 1):\n",
        "        # for i in range(1, 2):\n",
        "          training_pair = training_pairs[i - 1]\n",
        "          input_tensor = training_pair[0]\n",
        "          target_tensor = training_pair[1]\n",
        "          input_char_indexes = training_char_indexes[i - 1]\n",
        "\n",
        "          loss = train(input_tensor, target_tensor, input_char_indexes, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "          print_loss_total += loss\n",
        "          plot_loss_total += loss\n",
        "\n",
        "          if i % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, i / len(train_pairs)), i, i / len(train_pairs) * 100, print_loss_avg))\n",
        "            \n",
        "          if i % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2HxgWKNDZuO",
        "colab_type": "text"
      },
      "source": [
        "We modify the `Evaluate` method to perform beam search decoding to generate the output sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01eiA9AKDuSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "    input_length = input_tensor.size()[0]\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    \n",
        "    input_char_indexes = charIndexesFromSentence(input_char, sentence)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoder_hidden = encoder(torch.LongTensor([input_char_indexes[ei]]).to(device), input_tensor[ei], encoder_hidden)\n",
        "      encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoded_batch = beamDecode(decoder_hidden.unsqueeze(1), decoder, encoder_outputs.unsqueeze(1))\n",
        "    \n",
        "    return decoded_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foxGGXPZ6Q2C",
        "colab_type": "text"
      },
      "source": [
        "### Train our improved model on train data (80% of total data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVooQtHupAck",
        "colab_type": "code",
        "outputId": "d394ff0d-cf27-41e0-9766-6b5a43325b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_size = 256\n",
        "char_embedding_dim = 25\n",
        "char_representation_dim = 25\n",
        "\n",
        "encoder1 = EncoderRNN(input_char.n_chars, input_lang.n_words, hidden_size, char_embedding_dim, char_representation_dim).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainEpochs(encoder1, attn_decoder1)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "0m 23s (1000 11%) 3.5204\n",
            "0m 45s (2000 23%) 2.9411\n",
            "1m 8s (3000 35%) 2.7717\n",
            "1m 31s (4000 47%) 2.6694\n",
            "1m 55s (5000 59%) 2.5656\n",
            "2m 18s (6000 70%) 2.4945\n",
            "2m 40s (7000 82%) 2.3554\n",
            "3m 3s (8000 94%) 2.3332\n",
            "Epoch 1\n",
            "3m 39s (1000 11%) 3.2928\n",
            "4m 2s (2000 23%) 2.1552\n",
            "4m 26s (3000 35%) 2.0582\n",
            "4m 50s (4000 47%) 2.0679\n",
            "5m 14s (5000 59%) 2.0292\n",
            "5m 37s (6000 70%) 1.9642\n",
            "6m 1s (7000 82%) 1.9984\n",
            "6m 24s (8000 94%) 1.9450\n",
            "Epoch 2\n",
            "6m 59s (1000 11%) 2.5595\n",
            "7m 23s (2000 23%) 1.7055\n",
            "7m 46s (3000 35%) 1.6831\n",
            "8m 9s (4000 47%) 1.7017\n",
            "8m 32s (5000 59%) 1.6377\n",
            "8m 55s (6000 70%) 1.6438\n",
            "9m 17s (7000 82%) 1.6181\n",
            "9m 40s (8000 94%) 1.6082\n",
            "Epoch 3\n",
            "10m 15s (1000 11%) 2.0922\n",
            "10m 38s (2000 23%) 1.3606\n",
            "11m 1s (3000 35%) 1.3258\n",
            "11m 24s (4000 47%) 1.3708\n",
            "11m 48s (5000 59%) 1.3452\n",
            "12m 11s (6000 70%) 1.3867\n",
            "12m 34s (7000 82%) 1.3300\n",
            "12m 57s (8000 94%) 1.3118\n",
            "Epoch 4\n",
            "13m 32s (1000 11%) 1.6942\n",
            "13m 55s (2000 23%) 1.1063\n",
            "14m 18s (3000 35%) 1.0954\n",
            "14m 41s (4000 47%) 1.0372\n",
            "15m 4s (5000 59%) 1.1021\n",
            "15m 27s (6000 70%) 1.1330\n",
            "15m 49s (7000 82%) 1.0777\n",
            "16m 13s (8000 94%) 1.1717\n",
            "Epoch 5\n",
            "16m 48s (1000 11%) 1.3150\n",
            "17m 12s (2000 23%) 0.8210\n",
            "17m 35s (3000 35%) 0.8731\n",
            "17m 58s (4000 47%) 0.8503\n",
            "18m 22s (5000 59%) 0.8831\n",
            "18m 46s (6000 70%) 0.8984\n",
            "19m 9s (7000 82%) 0.8996\n",
            "19m 32s (8000 94%) 0.9223\n",
            "Epoch 6\n",
            "20m 7s (1000 11%) 1.1112\n",
            "20m 30s (2000 23%) 0.6366\n",
            "20m 53s (3000 35%) 0.6811\n",
            "21m 16s (4000 47%) 0.7050\n",
            "21m 39s (5000 59%) 0.7515\n",
            "22m 2s (6000 70%) 0.7320\n",
            "22m 24s (7000 82%) 0.7495\n",
            "22m 47s (8000 94%) 0.8098\n",
            "Epoch 7\n",
            "23m 21s (1000 11%) 0.8890\n",
            "23m 44s (2000 23%) 0.5013\n",
            "24m 7s (3000 35%) 0.5644\n",
            "24m 30s (4000 47%) 0.5824\n",
            "24m 53s (5000 59%) 0.6158\n",
            "25m 16s (6000 70%) 0.5608\n",
            "25m 40s (7000 82%) 0.5869\n",
            "26m 2s (8000 94%) 0.6405\n",
            "Epoch 8\n",
            "26m 36s (1000 11%) 0.6462\n",
            "26m 59s (2000 23%) 0.4227\n",
            "27m 22s (3000 35%) 0.4532\n",
            "27m 44s (4000 47%) 0.4296\n",
            "28m 7s (5000 59%) 0.4893\n",
            "28m 30s (6000 70%) 0.4757\n",
            "28m 53s (7000 82%) 0.4565\n",
            "29m 16s (8000 94%) 0.4856\n",
            "Epoch 9\n",
            "29m 50s (1000 11%) 0.5244\n",
            "30m 13s (2000 23%) 0.3080\n",
            "30m 36s (3000 35%) 0.3352\n",
            "30m 59s (4000 47%) 0.3486\n",
            "31m 22s (5000 59%) 0.3320\n",
            "31m 45s (6000 70%) 0.3679\n",
            "32m 8s (7000 82%) 0.3901\n",
            "32m 31s (8000 94%) 0.3717\n",
            "Epoch 10\n",
            "33m 6s (1000 11%) 0.4313\n",
            "33m 29s (2000 23%) 0.2711\n",
            "33m 52s (3000 35%) 0.2409\n",
            "34m 15s (4000 47%) 0.2617\n",
            "34m 37s (5000 59%) 0.2763\n",
            "35m 0s (6000 70%) 0.2947\n",
            "35m 22s (7000 82%) 0.3148\n",
            "35m 45s (8000 94%) 0.3114\n",
            "Epoch 11\n",
            "36m 19s (1000 11%) 0.3552\n",
            "36m 42s (2000 23%) 0.1998\n",
            "37m 5s (3000 35%) 0.1954\n",
            "37m 28s (4000 47%) 0.1923\n",
            "37m 50s (5000 59%) 0.2194\n",
            "38m 13s (6000 70%) 0.2384\n",
            "38m 35s (7000 82%) 0.2253\n",
            "38m 57s (8000 94%) 0.2465\n",
            "Epoch 12\n",
            "39m 30s (1000 11%) 0.2523\n",
            "39m 53s (2000 23%) 0.1475\n",
            "40m 15s (3000 35%) 0.1801\n",
            "40m 37s (4000 47%) 0.1875\n",
            "41m 0s (5000 59%) 0.1763\n",
            "41m 22s (6000 70%) 0.1885\n",
            "41m 44s (7000 82%) 0.1867\n",
            "42m 7s (8000 94%) 0.2094\n",
            "Epoch 13\n",
            "42m 40s (1000 11%) 0.2349\n",
            "43m 2s (2000 23%) 0.1402\n",
            "43m 24s (3000 35%) 0.1440\n",
            "43m 46s (4000 47%) 0.1476\n",
            "44m 9s (5000 59%) 0.1422\n",
            "44m 31s (6000 70%) 0.1610\n",
            "44m 53s (7000 82%) 0.1646\n",
            "45m 16s (8000 94%) 0.1601\n",
            "Epoch 14\n",
            "45m 49s (1000 11%) 0.1935\n",
            "46m 11s (2000 23%) 0.1077\n",
            "46m 34s (3000 35%) 0.1167\n",
            "46m 56s (4000 47%) 0.1376\n",
            "47m 18s (5000 59%) 0.1292\n",
            "47m 40s (6000 70%) 0.1294\n",
            "48m 2s (7000 82%) 0.1391\n",
            "48m 24s (8000 94%) 0.1484\n",
            "Epoch 15\n",
            "48m 57s (1000 11%) 0.1566\n",
            "49m 20s (2000 23%) 0.1016\n",
            "49m 42s (3000 35%) 0.1121\n",
            "50m 4s (4000 47%) 0.1232\n",
            "50m 27s (5000 59%) 0.1000\n",
            "50m 49s (6000 70%) 0.1310\n",
            "51m 12s (7000 82%) 0.1285\n",
            "51m 34s (8000 94%) 0.1458\n",
            "Epoch 16\n",
            "52m 8s (1000 11%) 0.1539\n",
            "52m 30s (2000 23%) 0.0936\n",
            "52m 52s (3000 35%) 0.0949\n",
            "53m 15s (4000 47%) 0.1115\n",
            "53m 37s (5000 59%) 0.1196\n",
            "53m 59s (6000 70%) 0.0961\n",
            "54m 21s (7000 82%) 0.1213\n",
            "54m 44s (8000 94%) 0.1346\n",
            "Epoch 17\n",
            "55m 18s (1000 11%) 0.1122\n",
            "55m 40s (2000 23%) 0.0973\n",
            "56m 3s (3000 35%) 0.0872\n",
            "56m 26s (4000 47%) 0.1156\n",
            "56m 48s (5000 59%) 0.1063\n",
            "57m 11s (6000 70%) 0.1123\n",
            "57m 33s (7000 82%) 0.1086\n",
            "57m 56s (8000 94%) 0.0935\n",
            "Epoch 18\n",
            "58m 30s (1000 11%) 0.1408\n",
            "58m 53s (2000 23%) 0.0798\n",
            "59m 17s (3000 35%) 0.0869\n",
            "59m 40s (4000 47%) 0.1051\n",
            "60m 3s (5000 59%) 0.0804\n",
            "60m 26s (6000 70%) 0.0868\n",
            "60m 48s (7000 82%) 0.0978\n",
            "61m 11s (8000 94%) 0.1092\n",
            "Epoch 19\n",
            "61m 45s (1000 11%) 0.1208\n",
            "62m 9s (2000 23%) 0.0828\n",
            "62m 32s (3000 35%) 0.0834\n",
            "62m 55s (4000 47%) 0.0922\n",
            "63m 18s (5000 59%) 0.0916\n",
            "63m 40s (6000 70%) 0.0796\n",
            "64m 3s (7000 82%) 0.1069\n",
            "64m 26s (8000 94%) 0.0815\n",
            "showPlot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA-3ffOspAcV",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate and report BLEU scores for beam size of 5 on test data (20% of total data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5cwQQmqpakb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "43057a49-c0c3-45ec-b299-62e7d1cbb818"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "candidate_corpus = []\n",
        "references_corpus = []\n",
        "\n",
        "for pair in test_pairs:\n",
        "  # Evaluate pair\n",
        "  print('>', pair[0])\n",
        "  print('=', pair[1])\n",
        "  decoded_batch = evaluate(encoder1, attn_decoder1, pair[0])\n",
        "  output_sentence = ' '.join([output_lang.index2word[index.item()] for index in decoded_batch[0][0][1:-1]])\n",
        "  print('<', output_sentence)\n",
        "  print('')\n",
        "\n",
        "  # Append to corpus\n",
        "  candidate_corpus.append(output_sentence.split(' '))\n",
        "  references_corpus.append(references_corpus.split(' '))\n",
        "\n",
        "score = bleu_score(candidate_corpus, references_corpus)\n",
        "print('Bleu score: %.4f' % (score))"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-310-d6521065a220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcandidate_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreferences_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext.data.metrics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}