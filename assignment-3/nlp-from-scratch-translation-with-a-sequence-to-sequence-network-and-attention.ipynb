{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "nlp-from-scratch-translation-with-a-sequence-to-sequence-network-and-attention.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alanwuha/ce7455-nlp/blob/master/assignment-3/nlp-from-scratch-translation-with-a-sequence-to-sequence-network-and-attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kf6lYotpAas",
        "colab_type": "text"
      },
      "source": [
        "# NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0ohF3QFc-Sb",
        "colab_type": "text"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyVY5MIopAav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0iUnH9VpAa1",
        "colab_type": "text"
      },
      "source": [
        "### Load and Prepare Data\n",
        "\n",
        "The data for this project is a set of many thousands of English to French translation pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmdQD0tQpAa2",
        "colab_type": "code",
        "outputId": "11152c4d-219e-4c56-8fd8-4bf013b218f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-01 05:54:52--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 54.192.151.21, 54.192.151.109, 54.192.151.68, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|54.192.151.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip.1’\n",
            "\n",
            "data.zip.1          100%[===================>]   2.75M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-04-01 05:54:53 (90.4 MB/s) - ‘data.zip.1’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybACQRGQpAa6",
        "colab_type": "text"
      },
      "source": [
        "Similar to the character encoding used in the character-level RNN tutorials, we will be representing each word in a language as a one-hot vector, or giant vector of zeros except for a single one (at the index of the word). Compared to the dozens of characters that might exist in a language, there are many many more words, so the encoding vector is much larger. We will however cheat a bit and trim the data to only use a few thousand words per language.\n",
        "\n",
        "![diagram](https://pytorch.org/tutorials/_images/word-encoding.png)\n",
        "\n",
        "We'll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called `Lang` which has word -> index (`word2index`) and index -> word (`index2word`) dictionaries, as well as a count of each word `word2count` to use to later replace rare words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVYaTPe4pAa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = { 0: 'SOS', 1: 'EOS' }\n",
        "        self.n_words = 2 # Count SOS and EOS\n",
        "        \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "            \n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLuIjrBNpAbE",
        "colab_type": "text"
      },
      "source": [
        "The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7QYWG2opAbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e37cc299-d731-4533-b873-4fb3ca4ce4ec",
        "id": "vr8PjTrnh1A1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(unicodeToAscii(\"À l'aide !\"))\n",
        "print(normalizeString(\"À l'aide !\"))\n",
        "\n",
        "print(normalizeString(\"Go.\"))\n",
        "print(normalizeString(\"Va !\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A l'aide !\n",
            "a l aide !\n",
            "go .\n",
            "va !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhLEvBd-pAbP",
        "colab_type": "text"
      },
      "source": [
        "To read the data file we will split the file into lines, and then split lines into pairs. The files are all English -> Other Language, so if we want to translate from Other Language -> English I added the `reverse` flag to reverse the pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQiqvKdSpAbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False): # e.g. lang1 = eng, lang2 = fra\n",
        "    print(\"Reading lines...\")\n",
        "    \n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "    \n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    \n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "        input_char = Char(lang2)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "        input_char = Char(lang1)\n",
        "        \n",
        "    return input_lang, output_lang, input_char, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-08MGdXmpAbU",
        "colab_type": "text"
      },
      "source": [
        "Since there are a _lot_ of example sentences and we want to train something quickly, we'll trim the data set to only relatively short and simple sentence. Here the maximum length is 10 words (that includes ending punctuation) and we're filtering to sentences that translate to the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced earlier)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q965XNzpAbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p): # e.g. p = ['go.', 'va !']\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRcfjbwtpAbZ",
        "colab_type": "text"
      },
      "source": [
        "The full process for preparing that data is:\n",
        "- Read text file and split into lines, split lines into pairs\n",
        "- Normalize text filter by length and content\n",
        "- Make word lists from sentences in pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YdVVufWmpAba",
        "colab_type": "code",
        "outputId": "1953d4d8-63e7-4fe6-ce41-4a89f22aed90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, input_char, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words and chars...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "        input_char.addSentence(pair[0])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    print(\"Counted chars:\")\n",
        "    print(input_char.name, input_char.n_chars)\n",
        "    \n",
        "    return input_lang, output_lang, input_char, pairs\n",
        "\n",
        "input_lang, output_lang, input_char, pairs = prepareData('eng', 'fra', True)\n",
        "\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words and chars...\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "Counted chars:\n",
            "fra 29\n",
            "['vous etes tres marrant .', 'you re very funny .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MwV4fb0pAbe",
        "colab_type": "code",
        "outputId": "f490364f-b1de-44b6-d3d8-20e0eb1aa273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "print(input_char.char2index)\n",
        "print(input_char.char2count)\n",
        "print(input_char.index2char)\n",
        "print(input_char.n_chars)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'j': 0, 'a': 1, 'i': 2, 'n': 3, 's': 4, '.': 5, 'e': 6, 'v': 7, 'b': 8, 'c': 9, 'u': 10, 'g': 11, 'r': 12, 'o': 13, 'f': 14, 'm': 15, 't': 16, 'h': 17, '!': 18, 'l': 19, 'd': 20, 'p': 21, 'z': 22, 'x': 23, 'y': 24, 'q': 25, 'k': 26, '?': 27, 'w': 28}\n",
            "{'j': 4774, 'a': 13819, 'i': 15983, 'n': 15628, 's': 27771, '.': 10262, 'e': 40222, 'v': 4630, 'b': 1642, 'c': 5537, 'u': 16566, 'g': 1742, 'r': 12076, 'o': 13499, 'f': 2316, 'm': 6719, 't': 15608, 'h': 1468, '!': 197, 'l': 9856, 'd': 5313, 'p': 6098, 'z': 407, 'x': 747, 'y': 415, 'q': 1192, 'k': 37, '?': 145, 'w': 13}\n",
            "{0: 'j', 1: 'a', 2: 'i', 3: 'n', 4: 's', 5: '.', 6: 'e', 7: 'v', 8: 'b', 9: 'c', 10: 'u', 11: 'g', 12: 'r', 13: 'o', 14: 'f', 15: 'm', 16: 't', 17: 'h', 18: '!', 19: 'l', 20: 'd', 21: 'p', 22: 'z', 23: 'x', 24: 'y', 25: 'q', 26: 'k', 27: '?', 28: 'w'}\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omy7HbdcpxPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wordIndexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = wordIndexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q5vqey1pAb0",
        "colab_type": "text"
      },
      "source": [
        "### The Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdbqxzumpAb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UEvTmt8pAb5",
        "colab_type": "text"
      },
      "source": [
        "### Attention Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtPmQBvcpAb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "        \n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "        \n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "        \n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "        \n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        \n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        \n",
        "        return output, hidden, attn_weights\n",
        "    \n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuIByMVfpAca",
        "colab_type": "text"
      },
      "source": [
        "### Plotting results\n",
        "\n",
        "Plotting is done with matplotlib, using the array of loss values `plot_losses` saved while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuK6-GWApAca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "def showPlot(points):\n",
        "    print('showPlot')\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locater puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtm7keUhpAcQ",
        "colab_type": "text"
      },
      "source": [
        "This is a helper function to print time elapsed and estimated time remaining given the current time and progress %."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdnEx96qpAcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = s // 60\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULnxkv_TkYmX",
        "colab_type": "text"
      },
      "source": [
        "## Here's What's Changed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PNMvZqupAbj",
        "colab_type": "text"
      },
      "source": [
        "### The CNN Model for Generating Character Embeddings\n",
        "\n",
        "Consider the word 'cat', we pad it on both ends to get our maximum word length (this is mainly an implementation quirk since we can't have variable length layers at run time, our algorithm will ignore the pads).\n",
        "\n",
        "We then apply a convolution layer on top that generates spatial coherence across characters, we use a maxpool to extract meaningful features out of our convolution layer. This now gives us a dense vector representation of each word.\n",
        "\n",
        "__This representation will then be concatenated with the word embedding to become the input of the GRU layer in EncoderRNN__.\n",
        "\n",
        "![cnn_model](https://raw.githubusercontent.com/TheAnig/NER-LSTM-CNN-Pytorch/master/images/cnn_model.png)\n",
        "\n",
        "This snippet shows us how the CNN is implemented in PyTorch.\n",
        "\n",
        "```\n",
        "self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=char_representation_dim, kernel_size=(3, char_embedding_dim), padding=(2, 0))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O27J5z9xh2ey",
        "colab_type": "text"
      },
      "source": [
        "We define a new `Char` class that stores the char2index, char2count, and index2char dictionaries for a given language to be used for character-level encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6qWLGLfpAbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Char:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.char2index = {}\n",
        "        self.char2count = {}\n",
        "        self.index2char = {}\n",
        "        self.n_chars = 0\n",
        "        \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "            \n",
        "    def addWord(self, word):\n",
        "        for char in word:\n",
        "            self.addChar(char)\n",
        "            \n",
        "    def addChar(self, char):\n",
        "        if char not in self.char2index:\n",
        "            self.char2index[char] = self.n_chars\n",
        "            self.char2count[char] = 1\n",
        "            self.index2char[self.n_chars] = char\n",
        "            self.n_chars += 1\n",
        "        else:\n",
        "            self.char2count[char] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFCjZYqtqL3l",
        "colab_type": "text"
      },
      "source": [
        "We add two new methods `charIndexesFromSentence` and `charIndexesFromWord` to retrieve character indexes for a given input sentence for be used for our character-level encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC6OW8jHqLLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def charIndexesFromSentence(char, sentence):\n",
        "    return [charIndexesFromWord(char, word) for word in sentence.split(' ')]\n",
        "\n",
        "def charIndexesFromWord(char, word):\n",
        "    return [char.char2index[character] for character in word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAsK9XHypAcF",
        "colab_type": "code",
        "outputId": "68daa70d-745b-4c54-9484-4490b2825e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "sentence = 'je t aime'\n",
        "print(sentence)\n",
        "print(charIndexesFromSentence(input_char, sentence))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "je t aime\n",
            "[[0, 6], [16], [1, 2, 15, 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GibMll--lA07",
        "colab_type": "text"
      },
      "source": [
        "### The Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmP2nw1geG-y",
        "colab_type": "text"
      },
      "source": [
        "We modify the original EncoderRNN to include a character-level encoder to generate a character representation given an input word. This character representation will then be concatenated with the word embedding and passed as input into the GRU layer to generate the output and hidden vectors for each word in a sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0rMmhzZpAbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, n_chars, n_words, hidden_size, char_embedding_dim=25, char_representation_dim=25):\n",
        "        \"\"\"\n",
        "        Input parameters:\n",
        "            n_chars = Number of unique characters in input language\n",
        "            n_words = Number of unique words in input language\n",
        "            hidden_size = Dimension of GRU input and output.\n",
        "            char_embedding_dim = Dimension of the character embeddings\n",
        "            char_representation_dim = Output dimension from the CNN encoder for character\n",
        "        \"\"\"\n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "        # Parameters\n",
        "        self.n_chars = n_chars\n",
        "        self.char_embedding_dim = char_embedding_dim\n",
        "        self.char_representation_dim = char_representation_dim\n",
        "        self.n_words = n_words\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Character-level encoder\n",
        "        self.char_embedding_layer = nn.Embedding(n_chars, char_embedding_dim)\n",
        "        self.char_cnn3_layer = nn.Conv2d(in_channels=1, out_channels=char_representation_dim, kernel_size=(3, char_embedding_dim), padding=(2, 0))\n",
        "        \n",
        "        # Word embedding layer\n",
        "        self.word_embedding_layer = nn.Embedding(n_words, hidden_size - char_representation_dim) # Dimension of the word embeddings is automatically derived as hidden_size - char_representation_dim\n",
        "        \n",
        "        # GRU layer\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "        # Weights\n",
        "        self.initEmbedding(self.char_embedding_layer.weight)\n",
        "        \n",
        "    def forward(self, char_indexes, word_index, hidden):\n",
        "        # Get char representation\n",
        "        char_embedding = self.char_embedding_layer(char_indexes).unsqueeze(1)\n",
        "        char_cnn3 = self.char_cnn3_layer(char_embedding).squeeze(-1).unsqueeze(1)\n",
        "        char_representation = F.max_pool2d(char_cnn3, kernel_size=(1, char_cnn3.size(-1))).squeeze(-1)\n",
        "\n",
        "        # Get word embedding\n",
        "        word_embedding = self.word_embedding_layer(word_index).view(1, 1, -1)\n",
        "\n",
        "        # Concatenate char representation with word embedding\n",
        "        combined = torch.cat((char_representation, word_embedding), dim=2)\n",
        "\n",
        "        # Feed combined and hidden to GRU\n",
        "        output, hidden = self.gru(combined, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "    \n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "    def initEmbedding(self, input_embedding):\n",
        "      \"\"\"\n",
        "      Initialize embedding\n",
        "      \"\"\"\n",
        "      bias = np.sqrt(3.0 / input_embedding.size(1))\n",
        "      nn.init.uniform_(input_embedding, -bias, bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA-3ffOspAcV",
        "colab_type": "text"
      },
      "source": [
        "### Training the Model\n",
        "\n",
        "We modify `TrainIter` to train on 80% of the training data for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NorkrizapAcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, char_cnn3, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    char_cnn3_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    \n",
        "    training_pairs = []\n",
        "    training_char_indexes = []\n",
        "    for i in range(n_iters):\n",
        "        pair = random.choice(pairs)\n",
        "        training_pairs.append(tensorsFromPair(pair))\n",
        "        training_char_indexes.append(charIndexesFromSentence(input_char, pair[0]))\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        input_char_indexes = training_char_indexes[iter - 1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, input_char_indexes, encoder, char_cnn3,\n",
        "                     decoder, encoder_optimizer, char_cnn3_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx0-LqqZpAcJ",
        "colab_type": "text"
      },
      "source": [
        "We modify the encoder's forward pass method (line 24) to take in character indexes for each input word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJhU76afpAcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, input_char_indexes, encoder, char_cnn3, decoder, encoder_optimizer, char_cnn3_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    char_cnn3_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    # Pad input_char_indexes with zero indexes if sequence has fewer than max_length words\n",
        "    if len(input_char_indexes) < max_length:\n",
        "      input_char_indexes += [[0]] * (max_length - len(input_char_indexes))\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        # Modify encoder forward pass method to take in character indexes of the input word\n",
        "        encoder_output, encoder_hidden = encoder(torch.LongTensor([input_char_indexes[ei]]).to(device), input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "        \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "\n",
        "            # Train using DecoderRNN\n",
        "            # decoder_output, decoder_hidden = decoder(\n",
        "            #     decoder_input, decoder_hidden)\n",
        "\n",
        "            # Train using AttnDecoderRNN\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            \n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "\n",
        "            # Train using DecoderRNN\n",
        "            # decoder_output, decoder_hidden = decoder(\n",
        "            #     decoder_input, decoder_hidden)\n",
        "\n",
        "            # Train using AttnDecoderRNN\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            \n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    char_cnn3_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LOiKHL0jN-B",
        "colab_type": "text"
      },
      "source": [
        "### Training and Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVooQtHupAck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "847ab4b2-7b1f-4340-f91b-f52119447723"
      },
      "source": [
        "hidden_size = 256\n",
        "char_embedding_dim = 25\n",
        "char_representation_dim = 25\n",
        "\n",
        "encoder1 = EncoderRNN(input_char.n_chars, input_lang.n_words, hidden_size, char_embedding_dim, char_representation_dim).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, char_cnn3, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2m 12s (- 30m 50s) (5000 6%) 2.8141\n",
            "4m 18s (- 27m 57s) (10000 13%) 2.2201\n",
            "6m 25s (- 25m 40s) (15000 20%) 1.8858\n",
            "8m 31s (- 23m 25s) (20000 26%) 1.6058\n",
            "10m 36s (- 21m 13s) (25000 33%) 1.4286\n",
            "12m 41s (- 19m 2s) (30000 40%) 1.2735\n",
            "14m 47s (- 16m 53s) (35000 46%) 1.1322\n",
            "16m 52s (- 14m 45s) (40000 53%) 1.0206\n",
            "18m 55s (- 12m 37s) (45000 60%) 0.8901\n",
            "20m 59s (- 10m 29s) (50000 66%) 0.8215\n",
            "23m 2s (- 8m 22s) (55000 73%) 0.7567\n",
            "25m 6s (- 6m 16s) (60000 80%) 0.6757\n",
            "27m 12s (- 4m 11s) (65000 86%) 0.6197\n",
            "29m 18s (- 2m 5s) (70000 93%) 0.5856\n",
            "31m 23s (- 0m 0s) (75000 100%) 0.5425\n",
            "showPlot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKheDGgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}